\cleardoublepage
\chapter{Introduction}
\label{ch:introduction}
In his 1963 book, \textit{Formalized Music}, Composer, Engineer, and
Architect, Iannis Xenakis described the foundation for his own
reinterpretation of conventional music theory:
\begin{quotation}
  ``All sound is an integration of grains, of elementary sonic
  particles, of sonic quanta. Each of these elementary grains has a
  threefold nature: duration, frequency, and intensity.''
\end{quotation}
Instead of using high-level musical concepts like pitch and meter to
compose music, Xenakis posited, only the three elementary qualities
(frequency, duration and intensity) are necessary. Because it is
impractical to describe sounds as the sum of hundreds or thousands of
elementary sonic particles, he proposed that statistical and probabilistic
models should be used to define sounds at the macroscopic
level. Additionally, similar mathematical models should describe other
compositional concepts including rhythm, form, and melody. Xenakis
named this new style \textit{stochastic}, and he considered it a
generalization of existing music theory: High-level musical constructs
such as melody, harmony, and meter are mathematical abstractions of
the elementary sonic particles, and alternative abstractions such as
non standard tuning should exist as equals within the same mathematical
framework. Music composition, he claimed, requires a \emph{deep}
understanding of the mathematical relationship between sonic elements
and musical abstractions, and music composition necessarily involves
the formulation of new high-level musical constructs built from the
low-level sound elements.

\paragraph{}Xenakis' choice of frequency,
duration, and intensity as the three sonic elements is rational. Any
audio waveform can be represented as the sum of a (possibly infinite)
number of periodic sine waves. However, a waveform is not the same as
music, or even the same as sound. Sound is three-dimensional; sound
has a direction; sound exists in space.
% Given a propagation medium, and a time duration, sound travels a 
% certain distance in space. Given any distance in space, the
% wavelength
% of some frequency fills that space. 
The three projects described in this thesis each use stochastic
music as a base: \refmod, \polytempic, and \thesis. Each project is
directly inspired and influenced by Xenakis, but departs from his
foundational beliefs by treating time and space as equals,
and as true elements of music.


\section{\refmod}
\label{sec:refmod-intro}
\newthought {Music and space} are intimately connected. The first
project, described in \autoref{ch:ref-mod}, explores how we can
compose music using acoustic reflections in architectural space as a
medium. \refmod is a software tool that lets us design and experiment
with abstract acoustic lenses or ``sound mirrors'' in two
dimensions. It is directly inspired by the music and architecture of
Iannis Xenakis, a 20th century composer, music theorist, architect,
and engineer. His collected works provide guidance and perspective to
all the projects in this thesis.

\section{\polytempic}
\label{sec:polytempic-intro}

\newthought{Music and Time} are inseparable. All music flows through
time and depends on temporal constructs - the most common being meter
and tempo. Accelerating or decelerating tempi are common in many
styles of music, as are polyrhythms.  Music with multiple simultaneous
tempi or \textit{polytempic music} is less common, but still many
examples can be found. Fewer examples of music with simultaneous tempi
that shift relative to each other exist, however, and it is difficult
for musicians to accurately perform changing tempi in
parallel. Software is an obvious choice for composing complex and
challenging rhythms such as these, but existing compositional software
makes this difficult. \polytempic offers a solution to this challenge
by describing a strategy for composing music with multiple
simultaneous tempi that accelerate and decelerate relative to each
other. In \autoref{ch:polytempic} we derive an equation for smoothly
ramping tempi to converge and diverge as musical events within a
score, and show how this equation can be used as a stochastic process
to compose previously inaccessible sonorities.

\section{\thesis}
\label{sec:hypercompression-intro}
\newthought{We usually think of compression} in terms of
\emph{reduction}: We use data compression to reduce bit-rates and file
sizes and audio compression to reduce dynamic range. Record labels use
of dynamic range compression as a weapon in the \emph{loudness
  war}\sidenote[][-3cm]{``Loudness War'' is the popular name given to
  the trend of increasing perceived loudness in music recordings.
  Beginning in the 1990s, record labels have attempted to make their
  music louder than the competition, at the expense of audio
  fidelity.}\cite{Deruty2014a}, has resulted in some of today's music
recordings utilizing no more dynamic range than a 1909 Edison
cylinder.\cite{Katz2007} A deeper study of dynamic range compression,
however, reveals more subtle and artistic applications beyond that of
reduction. A skilled audio engineer can apply compression to
improve intelligibility, augment articulation, smooth a performance,
shape transients, extract ambience, de-ess vocals, balance multiple
signals, or even add distortion.\cite{Case2007} At its best, the
compressor is a tool for temporal shaping, rather than a tool for
dynamic reduction.

\thesis expands the traditional model of a dynamic range compressor to
include spatial shaping. While unconventional, spatial processing is a
very natural fit for the compression paradigm. Sound is a medium that
exists in time as well as in space.\sidenote{Converting measurement of
  sound from the cycles per second (in the temporal domain) to
  wavelength (in the spatial domain) is a common objective in
  acoustics and audio engineering practices. See \textit{The Sound
    Reinforcement Handbook} by G. Davis for examples.} The mathematics
and implementation of the Hypercompressor are described in detail in
\autoref{ch:hypercompressor}.

\section{Audio Engineering}
\label{sec:audio-engineering}

Today, just over 50 years after \textit{Formalized Music} was first
published, some of Xenakis' values are widely accepted, while others
are largely ignored. Computers and digital audio workstations (DAWs)
have become ubiquitous in music composition, production, and
performance. The tools for shaping sounds inside DAWs typically use
mathematical language such as frequency, milliseconds, and decibels,
necessitating an understanding of the mathematical representation of
sound. However, these sounds 

Synthesizers for creating musical sounds use simple waveforms,
and parameters for describing intensity and duration, but 

Musicians are increasingly required to understand
the mathematics of music.

Musical synthesizers build complex 

The distinction between musician and engineer is becoming increasingly
indistinct. 



Curious that the simplest tools for engineering audio, 


only exist in spacesound has a direction; sound exists in space. 


As many
musicians before Xenakis have found,


For a theory that was intended to generalize all
of music theory, it is surprising that Xenakis did not include 



At the beginning of the 20th century, there was a blossoming of
complexity, diversity, and invention in contemporary music
composition. Composers such as Debussy, Strauss, Schoenberg and
Stravinsky introduced and devleoped new ways to use harmony and rhythm
that built on the already transofmative works of Wagner in the late
19th century.



Igor Stravin



elements

pointless 

combine studio traditions with art music?

\newthought{In the 6th century B.C.}, Pythagoras discovered that
dividing a resonating string into simple mathematical ratios produced
harmonious musical intervals, while arbitrary ratios produced
dissonance.  His observation is probably the first of the many
explicit parallels between math and music that have been identified
since his time. Today, we describe musical pitches as integers within
a given tuning system. We describe the tuning system with a
mathematical formula that relates frequency to pitch. Musical time,
rhythm and meter are commonly described numerically. Musical
transposition and inversion both mirror mathematical functions and
borrow their names directly from mathematics.


As computers, amplifiers, and electronics become our primary tools for
creating manipulating, and performing music, mathematics and music
necessarily become more interconnected. Nearly every modern musical
recording, broadcast, and stream is the summation of many digital
recordings that have been individually discretized, sampled,
mathematically encoded, decoded, and digitally processed numerous
times before ever reaching our ears.\cite{Case2007} It is tempting to
describe music today as applied mathematics, but doing so betrays a
fundamental quality of music: Musicality does not correspond to % come
                                % back to this. replace musicality
                                % with some
mathematical elegance or precision. A musician will diverge from a
musical score to accomplish a particular artistic objective. A
vocalist does not abruptly change a pitch, but gently and carefully
lands on a pitch. A jazz musician might intentionally play slightly
behind the beat. A classical performer knows how to hold a fermata
just long enough. These intentional human artifacts are characterized
more by a feeling than by a formula.

% Because of the computer's inability..., new musical genres have emerged.
The computer's inability to understand feeling has led to new genres
of music like EDM\sidenote[][-25mm]{EDM (Electronic Dance Music)
  features formulaic and repetitive grooves locked to a temporal grid
  and often incorporates aggressive use of digital pitch correction,
  further exaggerating a robotic quality.}, Black
MIDI\sidenote[][-3mm]{Black MIDI is a musical genre that uses low
  fidelity audio samplers with a large number of MIDI notes over a
  short time. A single three minute Black MIDI track is likely to have
  over 100,000 MIDI notes. The name refers to the solid black
  appearance of the piano score.}, and Demoscene\sidenote{Demoscene
  music celebrates digital synthesis of compositionally complex
  electronic music and audio visualizations, using low level software
  interfaces and including the design and programming of the music
  synthesizers as part of the composition.}, but these styles of music
feature (rather than fix) the inhuman nature of computers. If we want
to integrate a computer into the performance or production of truly
expressive music, we must capture perceived feelings formulaically
and program the computer to reproduce them. This thesis describes
three different, but related projects that confront this challenge from
contrasting perspectives: \refmod, \polytempic, and \thesis.

%\paragraph{Performance}
\thesis was used in the live performance of \textit{De
  L'Exp\'{e}rience}, a new musical work by composer Tod Machover for
Narrator, Organ, and Electronics. During the premier at the Maison
Symphonique de Montr\'{e}al in Canada, \thesis was used to blend the
electronics with the organ and the acoustic space. 
A detailed description of how \thesis featured in this performance is
also discussed in \autoref{ch:hypercompressor}.


\section{Universality}
\label{sec:universality}
At the MIT Media Lab, we celebrate the study and practice of projects
that exist outside of established academic disciplines. The Media Lab
(and the media) have described this approach as interdisciplinary,
cross-disciplinary, anti-disciplinary, or post-disciplinary; rejecting
the clich\'{e} that academics must narrowly focus their studies
learning \textit{more and more about less and less}, and eventually
knowing \textit{everything about nothing}.  The projects described
here uphold the vision of both Xenakis and the Media Lab. Each chapter
documents the movitaions and implementation of a new tool for
manipulating space and sound. Each project draws from an assortment of
fields including music, mathematics, computer science, acoustics,
audio engineering and mixing, sound reinforcement, multimedia
production, and live performance. 

% How can we describe and document a project with such broad subject
% material? Within a single discipline, there is an accepted hierarchy
% of concepts, and we are expected to develop a \emph{deep}
% understanding that penetrates this hierarchy. We expect students to be
% literate in algebra, geometry and calculus before studying
% physics. When we describe a physics problem, we depend on an
% established collection of language, notation, and theory.

% This example reveals the curious tension between breadth and depth:
% The \textit{depth} of a disciplinary approach provides the language
% and abstraction that enable us to describe content and communicate at
% a high level. Depth is essential for solving non-trivial
% problems. However, solutions to the most complex and interesting
% real-world projects always span multiple disciplines. It appears we
% need breadth \emph{and} depth simultaneously. The impact of Iannis
% Xenakis and the success of the Philips Pavilion illustrate the
% efficacy of this approach. 

% \TODO{this thesis is an experiment in breadth and depth}

% One of the goals of this thesis is to
% bridge disciplines by describing the material in a way that is
% accessible to readers that are not experts in all the fields
% involved.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "CharlesHolbrow_MAS_Thesis"
%%% End:
