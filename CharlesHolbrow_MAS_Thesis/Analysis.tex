\clearpage
\chapter{Discussion and Analysis}
\label{ch:analysis}
In the previous chapters, we explore three new tools for creating and
processing music, their motivations, and implementations. The \refmod
in chapter \ref{ch:ref-mod}, proposes a new way to think about sound
in space. The \polytempic in chapter \ref{ch:polytempic} does the same
with musical time and meter. Chapters \ref{ch:hypercompressor} and
\ref{ch:experience} describe and implement a technique for modulating
music in in space with time as a reference. Each project project
builds on Iannis Xenakis' theory of \textit{stochastic music}. Each
project incorporates elements from other disciplines including
mathematics, computer science, acoustics, audio engineering and
mixing, sound reinforcement, multimedia production, and live
performance.

This final chapter discusses how each project succeeded, how each
project failed, and how future iterations can benefit from lessons
learned during the development process.

\section{Evaluation Criteria}
\label{sec:eval-criteria}
To evaluate a project of any kind, it is helpful to begin with a
purpose, and then determine the granularity and scope of the
evaluation.\cite{Saltzer2009} We might evaluate a music recording for
audio fidelity, for musical proficiency of the artist, for emotional
impact or resonance, for narrative, for technological inovation, for
creative vision, or for political and historical insight. This also
applies to the evaluation of technology.  We can evaluate the
suitability of a rack-mount analog to digital converter (ADC) for a
given purpose. A recording engineer may prefer the device impart a
favorable sound, while an acoustician may prefer that the device be
as neutral as possible. However, when evaluating an ADC or a music
recording, what we are most concerned with is the top level interface:
From most perspectives, we evaluate music by listening to it, and we
are not concerned which ADC was used to make the recording. When an
audio engineer, or acoustician evaluates an ADC, the device's
performance is more important than the exact layout of electronic
components inside the device.

Stochastic music theory is a \textit{vertical integration} of
mathematics, the physics of sound, psychoacoustics, and music. The
theory of stochastic music begins with the lowest level components of
sound, and ends with a creative musical product. What is a reasonable
perspective from which to evaluate stochastic music? From the
perspective of a listening, or performing the music? From the
perspective of a historian, evaluating the environment that led to the
composition, or studying the impact on music afterwords?  Should we try
to make sense of the entire technology stack, or try to evaluate every
layer of abstraction individually?

Somehow, between the low-level elements of sound and a musical
composition or performance, we transition from what is numerically
quantifiable to what we can only attempt to describe. The impossible
challenge of quantifying the unquantifiable is exactly what makes
music technology and audio engineering so alluring.

\TODO{What approach did I use?} I avoid comparative analysis, or
evaluation based on any kind of rubrik. 

%  Does the unit have an appropriate number and type of audio outputs suit
% our needs (such as TRS, XLR, and USB)? Does it perform reliably? Does
% it have a neutral or favorable impact on the sound? The results of our
% evaluation will depend on our purpose. If the purpose of the device is
% for playback of audio in a live performance context, the best choice
% will be different than if we want to use the unit for mixing in a
% recording studio.

\section{\refmod}
This project provides a single abstract interface that approaches
composition of space (architecture) and the composition of music at
the same time. The forms that it makes are familiar from the ruled
surfaces seen in Xenakis compositions, and early sketches of the
Philips Pavilion. In musical mode, we can think of the x and y axes
representing time and pitch. In architectural mode the canvas might
represent the floor plan of spaces we are designing.

While it is interesting to switch our perspective between the two
modes, there is not a clear connection from one to the other. A
carefully designed surface or reflection in one mode would be quite
arbitrary in the other mode. The reason that the interface is capable
of working in both modes is because it is so minimalist, that it does
not commit to one or the other. This is not a complete failing: The
tool was really designed to be a brainstorming aid at the very
beginning of the design process. It can be much simpler and quicker to
use that proper architectural software, as a means of creating
abstract shapes, similar to sketching on paper, before turning to
specialized software for more detailed design.

\paragraph{Curves, Constraints, and Simplicity} Despite the
shortcomings in this project, the parts that worked well and make a
good starting point for future iterations. There's something
intangible, but simple and \textit{fun} about the user
interface. There is only one input action; dragging a control
point. It is immediately clear what each control point does when it is
moved. It is easy to not even notice that there are five different
types of control points and each has slightly different behavior. It
is very intuitive to adjust a reflection surface such that the red
beams \textit{focus} on a certain point, and then re-adjust a
reflection surface so that they diverge chaotically. There is
something fascinating about how the simple movements intuitively
produce simultaneously coordinated or chaotic results. The response
might be described as \textit{stochastic}!

The red ``sound lines'' have three degrees of freedom: Position,
direction, and length. We can point the rays in any direction we like,
but, their movement is somewhat constrained.  The projection angle is
locked to 30 degrees, and the number of beams is always 8. Most of the
flexibility from the interface comes from the reflective surfaces.

It is easier to draw a curving reflective surface than a strait
one. If you make a special effort, it is possible to make one of the
surfaces straight, but just like drawing a line on a paper with a pen,
curved surfaces come more naturally. However, the curves in the \refmod do not
come naturally because they are following an input gesture like most
``drawing'' interfaces, but because of the simple mathematics in the
of the Bezier curves. Similarly, if we consider the red lines to be
notes on a time/pitch axis, the default interpretation is stochastic
glissandi rather than static pitches. Most musical software assumes
static pitches by default, and most architectural software assumes
strait lines by default.

\paragraph{Next Steps}
The obvious next steps, for this project, are correcting the
shortcomings described above. It could be made to work in three
dimensions, and model precise propagation of sound, rather than a very
simplified abstraction: It could become a proper acoustical
simulator. Another possibility is playing the sound is turning it into
a musical instrument where we can hear the stochastic glissandi in
realtime. These options are not necessarily mutually exclusive, but as
the interface becomes tailored to a more specific application, our
ability to think about the content as abstract representations also
breaks down. The ideal of software that is equally well equipped to
compose music and to imagine architectural spaces is probably
unrealistic. The beauty of the abstract representation of music
composition, is that \textit{any} visual representation of music is
quite abstract.

However, the direction I would like to take this in is not 

% Describe where I want to take this.
\section{\polytempic}
This chapter presents a very pure and elegant solution to a very
complex problem. But is it important? Is it not enough to just change
tempo with any of the other techniques presented in section
\ref{sec:background-polytempi}? If a performer cannot play precise tempo
curves anyway, what is this actually for?

Western polytempic music as defined in this chapter has existed for
only slightly over than one century, and there is certainly room for
new explorations. The oldest example in of western polytempic music is
in by Charles Ives in his 1906 piece, \textit{Central Park in the
  Dark}.\cite{Greschak2003} In the piece, the string section
represents nighttime darkness, while the rest of the orchestra
represents the sounds of central park at night. Beginning at measure
64, Ives leaves a note in the score, describing how the orchestra
accelerates, while the string section plays a constant tempo:
\begin{quotation}
  From measure 64 on, until the rest of the orchestra has played
  measure 118, the relation of the string orchestra's measures to
  those of the other instruments need not and cannot be written down
  exactly, as the gradual accelerando of all but the strings cannot be
  played in precisely the same tempi each time.
\end{quotation}
Ives acknowledges that there is no notation to describe the effect
that he wants, and that musicians are not capable of playing the
transition in a precise way. In this example, it is not important that
the that the simultaneous tempi have a precise rhythmic
relationship. Ives' use of paralel tempi is a graceful one. He
achieves a particular effect without requiring the musicians to do
something so unnatural as accelerate and decelerate relative to each
other, and then resynchronize at certain points. 

All polytempic compositions must grapple with the issue of
syncronicity, and most are less elegant than \textit{Central Park in
  the Dark}. Stockhausen's \textit{Gruppen} uses polytempi very
aggressively, going to great lengths to ensure that the three
orchestras are rhythmically synchronized and desynchronize in just the
right way.  If Stockhausen had been able to control the syncronicity
of the tempo precisely, it seems likely that he would have wanted
to try it. At least he would have been interested in experimenting with
\polytempic in other compositions.

\paragraph{Next Steps} Some music (and perhaps stochastic music in
particular) may be more interesting or influential from a theoretical
perspective than for the music itself in isolation. It could be that
the possibilities unlocked through the equations derived in
\autoref{ch:polytempic} are not different enough from the
approximations used by Nancarrow and Cage. Or that it is unrealistic
to direct performers to play them accurately enough to perceive the
difference.

However it is surprising that current digital tools for composition do
not let us even \emph{try} \polytempic. If we want to hear what tempo
transitions like the ones describe here sound like using digital
technology, there is no software that lets us do so, and we are still
forced to approximate. 

Audio programming languages like Max and SuperCollider let us code
formulaic tempi into our compositions, but equations like the ones
derived here are still required. I could not find any any mathematical
technique that lets us create tempo accelerations that fit the
constraints described in \autoref{ch:polytempic}, or any musical
example that proposed to have found another solution.

For simple cases, approximation is probably acceptable. If a musician
is incapable of playing the part, we are also likely incapable of
hearing the subtleties that distinguish an approximation from a
perfect performance. However, if we want lage collections of
simultaneous polytempi, like the ones shown in
figures~\ref{fig:polytempic-transition}
and~\ref{fig:polytempic-transition-3}, the approximations possible
with transcriptions, or the approximations of an unassisted human
performers are not precise enough.

\paragraph{Stochastic Theory} The study of \polytempic reveals what is
probably the greatest strength of stochastic music theory. A vertical
integration of the theory of sound and music lets us experience music
from a different perspective, and discover missed opportunities along the
way. 

\section{\thesis}
The design and development of the hypercompressor happened in parallel
with pre-production for \textit{De L'Exp\'{e}rience}. Often design
decisions were based on the factors involved with this one project,
not the most general case. The resulting project leave significant
design questions surrounding ambisonic dynamic range compression
unanswered.  For example: What it the best way to detect and attenuate
a region on our surround spere that is an unusual or elongated shape?
Should the compressor attempt to attenuate the narrow region only?
Should we the center of the region be attenuated by the same amount as
the very edge? The decision to make the surround compressor warp the
surround image in addition to attenuating regions that exceed the
threshold was also chosen because it suited the use case.
\begin{itemize}
\item We could simply warp all sounds away from a region that exceeds
  the compression threshold without attenuating them at all. However,
  doing so would increase the perceived level of the sound coming from
  the opposite direction. We also run the risk of creating the sonic
  ping-poing of sound arbitrarily panning around us just for the sake
  of the excitement, but not serving any larger artistic goal. 
\item If we simply attenuate a region that exceeds the threshold, we
  are not taking advantage of the opportunities provided to us by
  surround sound in the first place. In side-chain mode, we risk
  hiding a compressed sound completely when we could simple warp that
  region of the surround field to a location where it can be heard
  more clearly.
\end{itemize}
The current implementation also does not handle the case when two
separate regions of the surround field both exceed the threshold. What
are the ideal results? 

Another use case that is handled is that
when two sounds at a right angle (for example, one sound straight in
front of the listener, and one sound 90\degree{} to the right) both
exceed the threshold. The current implementation behaves
\paragraph{Stochos}

\paragraph{\textit{De L'Exp\'{e}rience}}
The main goal, of using the Hypercompressor was to blend the
electronic textures with the sound of the Pierre B\'{e}ique organ in
Tod Machover's composition . The chosen approach as to give the
electronics a sense of motion that the organ, (who's sound is awe
inspiring, but also somewhat static) cannot produce; thus the
electronics can be heard moving \emph{around} the sound of the organ,
rather than being required to compete with the sound of the organ.
The first attempt at this goal, however was not a success.

The electronics were mixed to occupy as much of the surround sound
sphere as possible, filling the entire room with sound.  My original
idea was to spatially separate the organ and electronics by connecting
them to the Hypercompressor in side-chain mode.  When the organ was
playing it would \emph{push} the sound of the electronics to the back
of the room, making it easier to hear both timbres without either
masking the other.  During the \textit{De L'Exp\'{e}rience} rehearsal,
this was the first approach I tried, but the resulting surround
texture had a different problem: The sound of the organ and the sound
of the electronics were \emph{too} separate. They did not blend with
each other in space, but existed as two clearly distinct sources. The
final solution (described in \autoref{ch:hypercompressor}) was the
result of the unsatisfactory results from my first attempt. While it
did not end up working the way I anticipated, I consider the
Hypercompressor to have aided the blending of the organ and
electronics rather well. However, the beautiful blend of electronic
and acoustic sounds that we achieved would have been possible without
many other contributing factors, such as the expert composition of the
electronic textures.

\paragraph{Next Steps}

\section{overall}
It would appear that the main challenge with stochastic composition,
or vertical integration, or that of scope. 

Having mixed a bunch of stuff, for different contexts, the different
panning strategies in discrete channel, ambisonics, don't are not
better or worse. Stockhausen didn't really didn't need anything other than
discrete channel panning for Gesang. In fact the piece holds up very
well in stereo. I do think that there is a difference between actual
surround and 5.1, the latter resembling dual stereo more than actual
surround. 

% welp, not sure how well it actually
% worked. And I don't expect electronic instrument to ever replace
% acoustic instruments, although they may eventually equal them in
% expressivity. Initially thought it would work backwards

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "CharlesHolbrow_MAS_Thesis"
%%% End:
